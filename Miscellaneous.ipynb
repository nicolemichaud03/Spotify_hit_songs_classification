{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try out diff gridsearchcv parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing necessary tools, loading dataset, and preprocessing the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, accuracy_score, f1_score, confusion_matrix, classification_report, roc_curve, auc, ConfusionMatrixDisplay\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/dataset-of-10s.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['target', 'uri', 'artist', 'track'], axis=1)\n",
    "y = data['target']\n",
    "\n",
    "X = X.apply(lambda x : (x - x.min()) /(x.max() - x.min()), axis=0)\n",
    "X.head()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.25, random_state= 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying other models for baseline (KNN, logistic regression):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = KNeighborsClassifier()\n",
    "\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "train_preds = knn_model.predict(X_train)\n",
    "test_preds = knn_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Precision Score for KNN Classifier: 79.18%\n",
      "Testing Precision Score for KNN Classifier: 71.64%\n",
      "Training Accuracy Score for KNN Classifier: 84.14%\n",
      "Testing Accuracy Score for KNN Classifier: 76.0%\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Precision Score for KNN Classifier: {:.4}%\".format(precision_score(y_train, train_preds) * 100))\n",
    "print(\"Testing Precision Score for KNN Classifier: {:.4}%\".format(precision_score(y_test, test_preds) * 100))\n",
    "\n",
    "print(\"Training Accuracy Score for KNN Classifier: {:.4}%\".format(accuracy_score(y_train, train_preds) * 100))\n",
    "print(\"Testing Accuracy Score for KNN Classifier: {:.4}%\".format(accuracy_score(y_test, test_preds) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(fit_intercept=False, C=1e12, solver='liblinear')\n",
    "\n",
    "model_log = logreg.fit(X_train, y_train)\n",
    "\n",
    "y_hat_train_log = logreg.predict(X_train)\n",
    "y_hat_test_log = logreg.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training precision score for logistic regression model: 73.67%\n",
      "Testing precision score logistic regression model: 72.91%\n",
      "Training accuracy score logistic regression model: 78.93%\n",
      "Testing accuracy score logistic regression model:78.12%\n"
     ]
    }
   ],
   "source": [
    "print(\"Training precision score for logistic regression model: {:.4}%\".format(precision_score(y_train, y_hat_train_log) * 100))\n",
    "print(\"Testing precision score logistic regression model: {:.4}%\".format(precision_score(y_test, y_hat_test_log) * 100))\n",
    "\n",
    "print(\"Training accuracy score logistic regression model: {:.4}%\".format(accuracy_score(y_train, y_hat_train_log)* 100))\n",
    "print(\"Testing accuracy score logistic regression model:{:.4}%\".format(accuracy_score(y_test, y_hat_test_log)* 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trying out various different parameters for GridSearchCV (baseline dt):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_tree = DecisionTreeClassifier(criterion='entropy', max_depth=5)\n",
    "baseline_tree.fit(X_train, y_train)\n",
    "y_hat_train = baseline_tree.predict(X_train)\n",
    "y_hat_test = baseline_tree.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_param_grid ={\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [None,5,10],\n",
    "    \"min_samples_split\": [0.2, 0.4, 0.6],\n",
    "    \"max_features\": [5, 10, 15],\n",
    "    'min_samples_leaf': [2, 4, 6, 8]\n",
    "    \n",
    "    \n",
    "}\n",
    "# Options: max. depth, min. samples split, min. leaf sample size, max. leaf nodes, max. features \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Score: 79.81%\n",
      "Mean Test Score: 79.38%\n",
      "Best Parameter Combination Found During Grid Search:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 10,\n",
       " 'max_features': 10,\n",
       " 'min_samples_leaf': 4,\n",
       " 'min_samples_split': 0.2}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_grid_search = GridSearchCV(baseline_tree , dt_param_grid, cv=3, return_train_score=True)\n",
    "\n",
    "dt_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Mean training score\n",
    "dt_gs_training_score = np.mean(dt_grid_search.cv_results_[\"mean_train_score\"])\n",
    "\n",
    "# Mean test score\n",
    "dt_gs_testing_score = dt_grid_search.score(X_test, y_test)\n",
    "\n",
    "print(f\"Mean Training Score: {dt_gs_training_score :.2%}\")\n",
    "print(f\"Mean Test Score: {dt_gs_testing_score :.2%}\")\n",
    "print(\"Best Parameter Combination Found During Grid Search:\")\n",
    "dt_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_param_grid2 ={\n",
    "    \"max_depth\": [8, 10, 12],\n",
    "    \"min_samples_split\": [0.1, 0.2, 0.3],\n",
    "    \"max_features\": [8, 10, 12],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    \n",
    "    \n",
    "}\n",
    "# Options: criterion, max. depth, min. samples split, min. leaf sample size, max. leaf nodes, max. features \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Score: 80.74%\n",
      "Mean Test Score: 79.31%\n",
      "Best Parameter Combination Found During Grid Search:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 10,\n",
       " 'max_features': 10,\n",
       " 'min_samples_leaf': 4,\n",
       " 'min_samples_split': 0.1}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_grid_search2 = GridSearchCV(baseline_tree , dt_param_grid2, cv=3, return_train_score=True)\n",
    "\n",
    "dt_grid_search2.fit(X_train, y_train)\n",
    "\n",
    "# Mean training score\n",
    "dt_gs_training_score2 = np.mean(dt_grid_search2.cv_results_[\"mean_train_score\"])\n",
    "\n",
    "# Mean test score\n",
    "dt_gs_testing_score2 = dt_grid_search2.score(X_test, y_test)\n",
    "\n",
    "print(f\"Mean Training Score: {dt_gs_training_score2 :.2%}\")\n",
    "print(f\"Mean Test Score: {dt_gs_testing_score2 :.2%}\")\n",
    "print(\"Best Parameter Combination Found During Grid Search:\")\n",
    "dt_grid_search2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_param_grid3 ={\n",
    "    \"max_depth\": [None,5,10],\n",
    "    \"max_features\": [5, 10, 15],\n",
    "    'min_samples_leaf': [4, 6, 8, 10],\n",
    "    \"min_samples_split\": [ 0.2, 0.4, 0.6],\n",
    "    \n",
    "}\n",
    "# Options: max. depth, min. samples split, min. leaf sample size, max. leaf nodes, max. features \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Score: 79.62%\n",
      "Mean Test Score: 78.06%\n",
      "Best Parameter Combination Found During Grid Search:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 10,\n",
       " 'max_features': 5,\n",
       " 'min_samples_leaf': 6,\n",
       " 'min_samples_split': 0.2}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_grid_search3 = GridSearchCV(baseline_tree , dt_param_grid3, cv=3, return_train_score=True)\n",
    "\n",
    "dt_grid_search3.fit(X_train, y_train)\n",
    "\n",
    "# Mean training score\n",
    "dt_gs_training_score3 = np.mean(dt_grid_search3.cv_results_[\"mean_train_score\"])\n",
    "\n",
    "# Mean test score\n",
    "dt_gs_testing_score3 = dt_grid_search3.score(X_test, y_test)\n",
    "\n",
    "print(f\"Mean Training Score: {dt_gs_training_score3 :.2%}\")\n",
    "print(f\"Mean Test Score: {dt_gs_testing_score3 :.2%}\")\n",
    "print(\"Best Parameter Combination Found During Grid Search:\")\n",
    "dt_grid_search3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8048249006564565"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a classifier with optimal values identified above\n",
    "dt = DecisionTreeClassifier(\n",
    "                            max_depth=5,\n",
    "                            min_samples_leaf=6,\n",
    "                            max_features = 5,\n",
    "                            random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7788393173852373"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(\n",
    "                            max_depth=3,\n",
    "                            min_samples_leaf=4,\n",
    "                            max_features = 10,\n",
    "                            min_samples_split = 0.2,\n",
    "                            random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trying out various different parameters for GridSearchCV (random forests model):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(max_features='sqrt',\n",
    "                               max_samples = 0.5,\n",
    "                               random_state=42)\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "y_hat_train3 = forest.predict(X_train)\n",
    "y_hat_test3 = forest.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_param_grid = {\n",
    "    \"max_depth\": [5, 7, 10],\n",
    "    \"max_features\": [5, 10, 15],\n",
    "    'min_samples_leaf': [4, 6, 8, 10],\n",
    "    \"min_samples_split\": [ 0.2, 0.4, 0.6],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 82.20%\n",
      "\n",
      "Optimal Parameters: {'max_depth': 5, 'max_features': 5, 'min_samples_leaf': 4, 'min_samples_split': 0.2}\n"
     ]
    }
   ],
   "source": [
    "rf_grid_search = GridSearchCV(forest, rf_param_grid, cv=3)\n",
    "rf_grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Testing Accuracy: {rf_grid_search.best_score_ :.2%}\")\n",
    "print(\"\")\n",
    "print(f\"Optimal Parameters: {rf_grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_param_grid2 = {\n",
    "    \"max_depth\": [None, 5],\n",
    "    \"max_features\": [5, 7, 10],\n",
    "    'min_samples_leaf': [4, 6, 8, 10]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 84.39%\n",
      "\n",
      "Optimal Parameters: {'max_depth': None, 'max_features': 10, 'min_samples_leaf': 6}\n"
     ]
    }
   ],
   "source": [
    "rf_grid_search2 = GridSearchCV(forest, rf_param_grid2, cv=3)\n",
    "rf_grid_search2.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Testing Accuracy: {rf_grid_search2.best_score_ :.2%}\")\n",
    "print(\"\")\n",
    "print(f\"Optimal Parameters: {rf_grid_search2.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8329465849729119"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(max_depth=None,\n",
    "                            max_features = 10,\n",
    "                            min_samples_leaf= 6,\n",
    "                            random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred_rf)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
